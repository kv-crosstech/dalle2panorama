# DALL·E 2 Panorama

[DALL·E 2](https://openai.com/dall-e-2/) can generate images of an immense quality, but it's only limited to square images.

This simple tool allows for semi-automatic (more of a "semi" for now) generation of wide-and-tall images using [DALL·E 2](https://openai.com/dall-e-2/), or, potentially, any other neural network with image inpainting functionality.

The UI design is a subject to change. Pull requests are greatly appreciated.



## Installing dependencies

Python version used 3.7.11 (but code should run in most, if not all, versions pf python >=3.7)

Python Package Index (PyPI) dependencies

```
pip install -r requirements.txt
```



## Usage

Create an empty directory and put there your source image. It can be an image generated by DALL-E-2. For now starting point for first iteration (you will see what I mean by this a bit later) was tested only with 1024x1024 PNG images.

For example you can load this one ![1_dalle](docs\images\1_dalle.png)

In the UI press `Load image`, then check desired directions for extending the image then click the `Prepare panorama` button. For example, let's use LEFT and RIGHT directions.

![UI_preparing](docs\images\UI_preparing.png)

If intermediate images generation has succeeded you will see that simple pop-up window:

![success](docs\images\success.png)

Press the `Next part ready` button when ready. You should see that image on-screen has changed - that indicates a part that's currently being edited. For me it's like this:

![UI_part1_RIGHT](docs\images\UI_part1_RIGHT.png)

The image already has transparent pixels to the right, and left side is taken from an original image (except the watermark, we don't want that to intervene with our generation, of course).

At this point you should see this exact image added to the folder:

![UI_part1_RIGHT_explorer](docs\images\UI_part1_RIGHT_explorer.png)

This is the image that we should upload to DALL·E 2's interface (that inconvenience will be removed in the upcoming release), write a prompt for it and then save it next to the currently editing part with the name `{image}_RIGHT_000_done.png` (just use the old filename and add _done to it). 

![UI_part1_RIGHT_explorer_done](docs\images\UI_part1_RIGHT_explorer_done.png)

Press `Next part ready` again, you'll see that image has changed. If the direction has changed, you will see that image is on other side now (LEFT side is next). All images for the RIGHT side (RIGHT_000, RIGHT_001 e.t.c.) will combine to the RIGHT_done image automatically. And you will be presented next image to generate (LEFT_000 in this example)

![UI_part1_LEFT](docs\images\UI_part1_LEFT.png)

Generate it, put next image next to original with name `{image}_LEFT_000_done.png` and then again press `Next part ready`. If all is done properly, you will see that in folder there's `{image}_LEFT_done.png` and `{image}_full.png` images. 

![UI_part1_LEFT_done](docs\images\UI_part1_LEFT_done.png)

And image on screen has changed to full generated image. That _full images is our target. Look at this:

![1_dalle_full](docs\images\1_dalle_full.png)

And we can repeat the process as many times as we want. Let's again generate Left and Right:

![1_dalle_full_full](docs\images\1_dalle_full_full.png)

This approach is a bit tedious for larger images:

![UP_DOWN_done](docs\images\UP_DOWN_done.png)

But it will be better in next releases, I promise ;)

![1_dalle_full_full_full](docs\images\1_dalle_full_full_full.png)



## Using API (in development)

There's an upcoming functionality (coming sooner, rather than later), currently some of it is stored in the `api` folder, for people that are curious enough to check it out. It will be used to generate images without boring things, like manual file uploading/saving, and most of other things that were discussed in current `Usage` paragraph.

This functionality currently relies on user to get Authorization header from OpenAI Labs and put it in `auth_header` variable. This functionality will be added in an upcoming release of the tool. It will ask you to write prompt for each part of the generated image and after all generations it will save to you `{image}_full.png` like in Usage. Without all the parts by default, but will be able to check the `Save intermediate` checkbox and they will be saved automatically as well.

After full release of [DALL·E 2](https://openai.com/dall-e-2/) there will be well documented API interface, like they did for text generation models, so this should improve even further later on.



## Known bugs

Watermark is removed in the merging process, so full image can be without DALL·E 2 watermark

User needs to restart program to start new panorama generation



## Roadmap

Roadmap is a subject to change and discuss. Any ideas on functionality/design/workflow are welcome.

### Next release
Add simple outpainting (you can put any image here, but the result will be only square image 1024x1024 because of DALL·E 2 limitation for such task)

Add API functionality to reduce user workload

Improve border generation. You can sometimes very clearly see where images were concatenated. This is mostly model limitation, but there's something we can do to mitigate it.

### Even further

Add support for local models (will try Disco diffusion, Latent Diffusion and Stable Diffusion when it releases)

Add other cloud models like Stable Diffusion (if they release API), Midjourney (if they release API and inpainting)

## Changelog

`v0.0.1` 
- Initial release to public
